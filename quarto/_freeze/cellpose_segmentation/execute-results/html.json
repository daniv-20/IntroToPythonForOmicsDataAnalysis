{
  "hash": "9d4bbe5fc315a7556e6b07f6fa8f494c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Cell Segmentation of MIF and H&E images with Cellpose in Python - WIP\"\nauthor: \"Dani V\"\nformat: \n  html:\n    toc: true\nexecute: \n  echo: fenced\n  freeze: auto\n---\n\nI need to figure out how to do segmentation with cellpose so I'm turning it into a tutorial. Therefore, this tutorial will be most applicable to people with similar systems (macOS, Apple M4 gpu or similar). All data here are publically available. \n\nFirst, make sure all necessary packages are installed (see 'programming in python' tutorial) as per cellpose instructions (link). Switch to your cellpose virtual environment. (For me it's ~/venvs/cellpose_mac).\n\nFirst, we need to check the GPU and load the model. The model needs to download and that can take some time. \n\n::: {#befdd59c .cell execution_count=1}\n```` { .cell-code}\n```{{python}}\nimport numpy as np\nfrom cellpose import models, core, io, plot\nfrom pathlib import Path\nfrom tqdm import trange\nimport matplotlib.pyplot as plt\n\nio.logger_setup() # run this to get printing of progress\n\n#Check if colab notebook instance has GPU access\nif core.use_gpu()==False:\n  raise ImportError(\"No GPU access, change your runtime\")\n\nmodel = models.CellposeModel(gpu=True)\n```\n\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n2025-10-29 15:03:17,147 [INFO] WRITING LOG OUTPUT TO /Users/dvaithilingam/.cellpose/run.log\n2025-10-29 15:03:17,148 [INFO] \ncellpose version: \t4.0.7 \nplatform:       \tdarwin \npython version: \t3.11.13 \ntorch version:  \t2.9.0\n2025-10-29 15:03:17,184 [INFO] ** TORCH MPS version installed and working. **\n2025-10-29 15:03:17,185 [INFO] ** TORCH MPS version installed and working. **\n2025-10-29 15:03:17,185 [INFO] >>>> using GPU (MPS)\n2025-10-29 15:03:17,824 [INFO] >>>> loading model /Users/dvaithilingam/.cellpose/models/cpsam\n```\n:::\n:::\n\n\n### Download Example Images\n\nWe can download the example images also. \n\n::: {#316f9f48 .cell execution_count=2}\n```` { .cell-code}\n```{{python}}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom cellpose import utils, io\n\n# download example 2D images from website\nurl = \"http://www.cellpose.org/static/data/imgs_cyto3.npz\"\nfilename = \"imgs_cyto3.npz\"\nutils.download_url_to_file(url, filename)\n\n# download 3D tiff\nurl = \"http://www.cellpose.org/static/data/rgb_3D.tif\"\nutils.download_url_to_file(url, \"rgb_3D.tif\")\n\ndat = np.load(filename, allow_pickle=True)[\"arr_0\"].item()\n\nimgs = dat[\"imgs\"]\nmasks_true = dat[\"masks_true\"]\n\nplt.figure(figsize=(8,3))\nfor i, iex in enumerate([9, 16, 21]):\n    img = imgs[iex].squeeze()\n    plt.subplot(1,3,1+i)\n    plt.imshow(img[0], cmap=\"gray\", vmin=0, vmax=1)\n    plt.axis('off')\nplt.tight_layout()\nplt.show()\n```\n\n````\n\n::: {.cell-output .cell-output-stderr}\n```\n\r  0%|          | 0.00/21.3M [00:00<?, ?B/s]\r  2%|▏         | 336k/21.3M [00:00<00:07, 3.05MB/s]\r  3%|▎         | 752k/21.3M [00:00<00:05, 3.72MB/s]\r  5%|▌         | 1.09M/21.3M [00:00<00:06, 3.38MB/s]\r  7%|▋         | 1.51M/21.3M [00:00<00:05, 3.52MB/s]\r  9%|▉         | 1.91M/21.3M [00:00<00:05, 3.63MB/s]\r 11%|█         | 2.33M/21.3M [00:00<00:05, 3.82MB/s]\r 13%|█▎        | 2.70M/21.3M [00:00<00:05, 3.83MB/s]\r 14%|█▍        | 3.06M/21.3M [00:00<00:05, 3.60MB/s]\r 16%|█▌        | 3.41M/21.3M [00:00<00:05, 3.55MB/s]\r 18%|█▊        | 3.76M/21.3M [00:01<00:05, 3.15MB/s]\r 19%|█▉        | 4.07M/21.3M [00:01<00:05, 3.16MB/s]\r 21%|██        | 4.38M/21.3M [00:01<00:05, 3.04MB/s]\r 22%|██▏       | 4.71M/21.3M [00:01<00:05, 3.14MB/s]\r 24%|██▍       | 5.14M/21.3M [00:01<00:04, 3.43MB/s]\r 26%|██▌       | 5.48M/21.3M [00:02<00:10, 1.53MB/s]\r 27%|██▋       | 5.73M/21.3M [00:02<00:10, 1.51MB/s]\r 28%|██▊       | 5.98M/21.3M [00:02<00:09, 1.70MB/s]\r 29%|██▉       | 6.21M/21.3M [00:02<00:10, 1.52MB/s]\r 30%|███       | 6.44M/21.3M [00:02<00:09, 1.56MB/s]\r 31%|███▏      | 6.66M/21.3M [00:02<00:09, 1.62MB/s]\r 33%|███▎      | 6.91M/21.3M [00:03<00:09, 1.61MB/s]\r 34%|███▎      | 7.12M/21.3M [00:03<00:08, 1.73MB/s]\r 35%|███▍      | 7.38M/21.3M [00:03<00:08, 1.64MB/s]\r 36%|███▌      | 7.58M/21.3M [00:03<00:09, 1.50MB/s]\r 37%|███▋      | 7.84M/21.3M [00:03<00:09, 1.49MB/s]\r 38%|███▊      | 8.04M/21.3M [00:03<00:09, 1.42MB/s]\r 39%|███▊      | 8.22M/21.3M [00:04<00:10, 1.31MB/s]\r 39%|███▉      | 8.35M/21.3M [00:04<00:22, 610kB/s] \r 40%|███▉      | 8.45M/21.3M [00:04<00:20, 653kB/s]\r 41%|████      | 8.66M/21.3M [00:04<00:15, 837kB/s]\r 41%|████▏     | 8.78M/21.3M [00:05<00:14, 876kB/s]\r 42%|████▏     | 8.90M/21.3M [00:05<00:13, 934kB/s]\r 43%|████▎     | 9.05M/21.3M [00:05<00:11, 1.08MB/s]\r 44%|████▍     | 9.38M/21.3M [00:05<00:07, 1.59MB/s]\r 46%|████▌     | 9.69M/21.3M [00:05<00:06, 1.93MB/s]\r 47%|████▋     | 10.0M/21.3M [00:05<00:05, 2.23MB/s]\r 49%|████▉     | 10.4M/21.3M [00:05<00:04, 2.51MB/s]\r 51%|█████     | 10.7M/21.3M [00:05<00:03, 2.87MB/s]\r 52%|█████▏    | 11.1M/21.3M [00:05<00:03, 3.11MB/s]\r 54%|█████▍    | 11.5M/21.3M [00:06<00:03, 3.37MB/s]\r 56%|█████▌    | 11.9M/21.3M [00:06<00:03, 3.10MB/s]\r 58%|█████▊    | 12.2M/21.3M [00:06<00:02, 3.22MB/s]\r 59%|█████▉    | 12.6M/21.3M [00:06<00:02, 3.32MB/s]\r 61%|██████    | 13.0M/21.3M [00:06<00:02, 3.37MB/s]\r 63%|██████▎   | 13.3M/21.3M [00:07<00:05, 1.59MB/s]\r 64%|██████▍   | 13.7M/21.3M [00:07<00:04, 1.97MB/s]\r 66%|██████▌   | 14.0M/21.3M [00:07<00:03, 2.23MB/s]\r 67%|██████▋   | 14.3M/21.3M [00:07<00:04, 1.46MB/s]\r 69%|██████▉   | 14.7M/21.3M [00:07<00:03, 1.88MB/s]\r 72%|███████▏  | 15.3M/21.3M [00:07<00:02, 2.50MB/s]\r 73%|███████▎  | 15.6M/21.3M [00:08<00:03, 1.62MB/s]\r 75%|███████▍  | 15.9M/21.3M [00:08<00:04, 1.27MB/s]\r 76%|███████▌  | 16.2M/21.3M [00:08<00:03, 1.46MB/s]\r 78%|███████▊  | 16.6M/21.3M [00:08<00:02, 1.86MB/s]\r 80%|███████▉  | 16.9M/21.3M [00:09<00:02, 2.22MB/s]\r 81%|████████▏ | 17.3M/21.3M [00:09<00:01, 2.55MB/s]\r 83%|████████▎ | 17.7M/21.3M [00:09<00:01, 2.82MB/s]\r 85%|████████▍ | 18.1M/21.3M [00:09<00:01, 3.04MB/s]\r 87%|████████▋ | 18.4M/21.3M [00:09<00:00, 3.28MB/s]\r 89%|████████▊ | 18.9M/21.3M [00:09<00:00, 3.58MB/s]\r 91%|█████████ | 19.2M/21.3M [00:09<00:00, 3.55MB/s]\r 92%|█████████▏| 19.6M/21.3M [00:10<00:00, 1.90MB/s]\r 94%|█████████▍| 20.0M/21.3M [00:10<00:00, 2.13MB/s]\r 95%|█████████▌| 20.3M/21.3M [00:10<00:00, 1.37MB/s]\r 97%|█████████▋| 20.6M/21.3M [00:10<00:00, 1.62MB/s]\r 99%|█████████▊| 21.0M/21.3M [00:10<00:00, 2.03MB/s]\r100%|██████████| 21.3M/21.3M [00:11<00:00, 1.97MB/s]\n\r  0%|          | 0.00/1.63M [00:00<?, ?B/s]\r 54%|█████▎    | 896k/1.63M [00:00<00:00, 9.17MB/s]\r100%|██████████| 1.63M/1.63M [00:00<00:00, 11.2MB/s]\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](cellpose_segmentation_files/figure-html/cell-3-output-2.png){width=758 height=278}\n:::\n:::\n\n\n## Run Cellpose-SAM\n\nAfter our images are downloaded, we can perform the segmentation using `model.eval()` and plot the results. \n\n::: {#921b3044 .cell execution_count=3}\n```` { .cell-code}\n```{{python}}\nmasks_pred, flows, styles = model.eval(imgs, niter=1000) \n```\n\n````\n\n::: {.cell-output .cell-output-stdout}\n```\n2025-10-29 15:03:30,869 [INFO] 0%|          | 0/24 [00:00<?, ?it/s]\n2025-10-29 15:04:09,198 [INFO] 42%|####1     | 10/24 [00:38<00:53,  3.83s/it]\n2025-10-29 15:04:28,931 [INFO] 42%|####1     | 10/24 [00:58<00:53,  3.83s/it]\n2025-10-29 15:04:44,716 [INFO] 58%|#####8    | 14/24 [01:13<00:56,  5.67s/it]\n2025-10-29 15:04:58,943 [INFO] 58%|#####8    | 14/24 [01:28<00:56,  5.67s/it]\n2025-10-29 15:06:25,969 [INFO] 79%|#######9  | 19/24 [02:55<00:57, 11.41s/it]\n2025-10-29 15:06:38,990 [INFO] 79%|#######9  | 19/24 [03:08<00:57, 11.41s/it]\n2025-10-29 15:07:03,187 [INFO] 96%|#########5| 23/24 [03:32<00:10, 10.76s/it]\n2025-10-29 15:07:08,979 [INFO] 100%|##########| 24/24 [03:38<00:00,  9.09s/it]\n```\n:::\n:::\n\n\n::: {#151384fc .cell execution_count=4}\n```` { .cell-code}\n```{{python}}\nfrom cellpose import transforms, plot\n\ntitles = [\n        \"Cellpose\", \"Nuclei\", \"Tissuenet\", \"Livecell\", \"YeaZ\",\n         \"Omnipose\\nphase-contrast\", \"Omnipose\\nfluorescent\",\n        \"DeepBacs\"\n    ]\n\nplt.figure(figsize=(12,6))\nly = 400\nfor iex in range(len(imgs)):\n    img = imgs[iex].squeeze().copy()\n    img = np.clip(transforms.normalize_img(img, axis=0), 0, 1) # normalize images across channel axis\n    ax = plt.subplot(3, 8, (iex%3)*8 + (iex//3) +1)\n    if img[1].sum()==0:\n        img = img[0]\n        ax.imshow(img, cmap=\"gray\")\n    else:\n        # make RGB from 2 channel image\n        img = np.concatenate((np.zeros_like(img)[:1], img), axis=0).transpose(1,2,0)\n        ax.imshow(img)\n    ax.set_ylim([0, min(400, img.shape[0])])\n    ax.set_xlim([0, min(400, img.shape[1])])\n\n\n    # GROUND-TRUTH = PURPLE\n    # PREDICTED = YELLOW\n    outlines_gt = utils.outlines_list(masks_true[iex])\n    outlines_pred = utils.outlines_list(masks_pred[iex])\n    for o in outlines_gt:\n        plt.plot(o[:,0], o[:,1], color=[0.7,0.4,1], lw=0.5)\n    for o in outlines_pred:\n        plt.plot(o[:,0], o[:,1], color=[1,1,0.3], lw=0.75, ls=\"--\")\n    plt.axis('off')\n\n    if iex%3 == 0:\n        ax.set_title(titles[iex//3])\n\nplt.tight_layout()\nplt.show()\n```\n\n````\n\n::: {.cell-output .cell-output-display}\n![](cellpose_segmentation_files/figure-html/cell-5-output-1.png){width=1142 height=523}\n:::\n:::\n\n\n",
    "supporting": [
      "cellpose_segmentation_files"
    ],
    "filters": [],
    "includes": {}
  }
}